{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 16:34:39.193710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-19 16:34:39.215096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-19 16:34:39.221641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-19 16:34:39.237546: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras import losses, metrics, layers, ops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_df = train_df[['agent1', 'agent2', 'EnglishRules', 'LudRules']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729344904.645974   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.704867   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.705276   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.706788   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.707096   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.707382   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.786677   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729344904.787092   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-19 16:35:04.787310: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1729344904.787497   23402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-19 16:35:04.787717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2784 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "100%|██████████| 1328/1328 [00:12<00:00, 108.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lud_preprocessor = layers.TextVectorization(\n",
    "    vocabulary='ludii_tokens.dic',\n",
    "    standardize='strip_punctuation'\n",
    ")\n",
    "\n",
    "eng_preprocessor = layers.TextVectorization(\n",
    "    vocabulary='eng_tokens.dic'\n",
    ")\n",
    "\n",
    "max_eng = 0\n",
    "max_lud = 0\n",
    "\n",
    "eng_uniques = train_set_df['EnglishRules'].unique()\n",
    "\n",
    "# for engrul in tqdm(eng_uniques):\n",
    "#     eng_vector = eng_preprocessor(engrul)\n",
    "#     max_eng = max(max_eng, eng_vector.shape[0])\n",
    "\n",
    "# print(max_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23613\n"
     ]
    }
   ],
   "source": [
    "lud_uniques = train_set_df['LudRules'].unique()\n",
    "\n",
    "EQPMNT_RE = r'\\(equipment'\n",
    "RULESTRIP_RE = r'[^a-zA-Z\\(\\)\\{\\}]'\n",
    "\n",
    "# for rule in lud_uniques:\n",
    "#     start = re.search(EQPMNT_RE, rule).span()[0]\n",
    "#     pure_rule = rule[start:]\n",
    "#     pure_rule = re.sub(RULESTRIP_RE, ' ', pure_rule)\n",
    "#     lud_vector = lud_preprocessor(pure_rule)\n",
    "#     max_lud = max(max_lud, lud_vector.shape[0])\n",
    "\n",
    "# print(max_lud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1_uniques = train_set_df['agent1'].unique()\n",
    "agent2_uniques = train_set_df['agent2'].unique()\n",
    "\n",
    "set(agent1_uniques) >= set(agent2_uniques)\n",
    "\n",
    "code_agent = {}\n",
    "agent_code = {}\n",
    "\n",
    "for id, agent in enumerate(agent1_uniques):\n",
    "    code_agent[id] = agent\n",
    "    agent_code[agent] = id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eng_vector.shape=(900,)\n",
    "\n",
    "lud_vector.shape=(23700,)\n",
    "\n",
    "agents_to_categorical.shape=(144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 900+23700+144 = 24744\n",
    "# defining input shape and input data distribution\n",
    "\n",
    "agents_len = 144\n",
    "engvector_len = 900\n",
    "ludvector_len = 23700\n",
    "\n",
    "enter = layers.Input(shape=(24744,))\n",
    "agent_input_layer = layers.Input(shape=(agents_len,))\n",
    "agent_input_data = ops.slice(enter, (0,), (agents_len,))\n",
    "\n",
    "engrul_input_data = ops.slice(enter, (agents_len,), (engvector_len,))\n",
    "\n",
    "ludrul_input_data = ops.slice(enter, (agents_len+engvector_len,), (ludvector_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English rules LSTM features extractor.\n",
    "# \n",
    "# Train set contains 384 preextracted features.\n",
    "# Let`s assume that game rule contains these features and ather that describes \n",
    "# Number of these features is unknown and needs to be discovered\n",
    "# presume that total amount of fetures, that are important for game result prediction is not less then double amount \n",
    "# of preextracted features and to be 800\n",
    "\n",
    "FEATURES_NUM = 128\n",
    "ENG_VECTOR_DIM = 128\n",
    "LUD_VECTOR_DIM = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EngRule LSTM\n",
    "\n",
    "engrul_input_layer = layers.Input(shape=(1, engvector_len,))\n",
    "flatten = layers.Flatten()(engrul_input_layer)\n",
    "eng_emb = layers.Embedding(input_dim=3692, output_dim=ENG_VECTOR_DIM)(flatten)\n",
    "eng_x = layers.LSTM(ENG_VECTOR_DIM)(eng_emb)\n",
    "# eng_x = layers.LSTM(ENG_VECTOR_DIM)(eng_x)\n",
    "eng_out = layers.Dense(FEATURES_NUM, activation='relu')(eng_x)\n",
    "\n",
    "# model = keras.Model(inputs=[enter], outputs=[eng_out])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LudRule LSTM\n",
    "\n",
    "ludrul_input_layer = layers.Input(shape=(1, ludvector_len,))\n",
    "flatten = layers.Flatten()(ludrul_input_layer)\n",
    "lud_emb = layers.Embedding(input_dim=1240, output_dim=LUD_VECTOR_DIM)(flatten)\n",
    "lud_x = layers.LSTM(LUD_VECTOR_DIM)(lud_emb)\n",
    "# lud_x = layers.LSTM(LUD_VECTOR_DIM)(lud_x)\n",
    "lud_out = layers.Dense(FEATURES_NUM, activation='relu')(lud_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemble = layers.Concatenate(axis=1)([agent_input_layer, eng_out, lud_out])\n",
    "x = layers.Dense(1200, activation='relu')(assemble)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "out = layers.Dense(1, activation='tanh')(x)\n",
    "\n",
    "model = keras.Model(inputs=[agent_input_layer, engrul_input_layer, ludrul_input_layer],\n",
    "                    outputs=[out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model,\n",
    "#                        show_shapes=True,\n",
    "#                        expand_nested=True,\n",
    "#                        show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GameDataGenerator(keras.utils.Sequence):\n",
    "    eqpmnt_re = r'\\(equipment'\n",
    "    rulestrip_re = r'[^a-zA-Z\\(\\)\\{\\}]'\n",
    "    engvector_len = 900\n",
    "    ludvector_len = 23700\n",
    "    \n",
    "    def __init__(self, list_IDs, dataframe, labels_dict, batch_size=32, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels_dict = labels_dict\n",
    "        self.df = dataframe[['agent1', 'agent2', 'EnglishRules', 'LudRules']]\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        self._agent_code = agent_code\n",
    "    \n",
    "    @property\n",
    "    def agent_code(self):\n",
    "        return self._agent_code\n",
    "\n",
    "    @agent_code.setter\n",
    "    def agent_code(self):\n",
    "        agents = self.df['agent1'].unique().tolist()\n",
    "        agents.sort()\n",
    "        ret = {}\n",
    "        for id_, agent in enumerate(agents):\n",
    "            ret[agent] = id_\n",
    "        self._agent_code = ret\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, batch_num):\n",
    "          # Generate indexes of the batch\n",
    "        indexes = self.indexes[batch_num*self.batch_size:(batch_num+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_ends(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def _lud_prepare(self, rule) -> str:\n",
    "        start = re.search(self.eqpmnt_re, rule).span()[0]\n",
    "        pure_rule = rule[start:]\n",
    "        pure_rule = re.sub(self.rulestrip_re, ' ', pure_rule)\n",
    "        return pure_rule\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X_agents = []\n",
    "        X_engvectors = []\n",
    "        X_ludvectors = []\n",
    "        y = []\n",
    "\n",
    "        agents_num = len(self.agent_code)\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            row = self.df.loc[ID]\n",
    "            agent1, agent2, engrul, ludrul = row\n",
    "\n",
    "            y.append(self.labels_dict[ID])\n",
    "\n",
    "            agent1_encoded = keras.utils.to_categorical(self.agent_code[agent1], agents_num)\n",
    "            agent2_encoded = keras.utils.to_categorical(self.agent_code[agent2], agents_num)\n",
    "            agents_encoded = np.hstack((agent1_encoded, agent2_encoded))\n",
    "            X_agents.append(np.array(agents_encoded))\n",
    "\n",
    "            engrul_vector = eng_preprocessor(engrul)\n",
    "            engrul_vector = keras.utils.pad_sequences((engrul_vector,), maxlen=self.engvector_len)\n",
    "            X_engvectors.append(engrul_vector)\n",
    "\n",
    "            ludrul_vector = lud_preprocessor(self._lud_prepare(ludrul))\n",
    "            ludrul_vector = keras.utils.pad_sequences((ludrul_vector,), maxlen=self.ludvector_len)\n",
    "            X_ludvectors.append(ludrul_vector)\n",
    "\n",
    "        return (np.array(X_agents), np.array(X_engvectors), np.array(X_ludvectors)), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffled_df = shuffle(train_df)\n",
    "\n",
    "labels = train_shuffled_df['utility_agent1'].to_dict()\n",
    "\n",
    "X_train, X_test = train_test_split(train_shuffled_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([220178,  22006, 135444, 159326, 104611,  64210,  16923,   9198, 117723,\n",
       "       220468,\n",
       "       ...\n",
       "         5131,   3621,  12832,  68695, 198282, 213114,  99701,  41744,  25523,\n",
       "        22318],\n",
       "      dtype='int64', length=174925)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = GameDataGenerator(X_train.index, train_shuffled_df, labels, batch_size=BATCH_SIZE)\n",
    "test_generator = GameDataGenerator(X_test.index, train_shuffled_df, labels, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=losses.MeanSquaredError(),\n",
    "              metrics=[metrics.MeanSquaredError()]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m60630/87462\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4:00:37\u001b[0m 538ms/step - loss: 0.1556 - mean_squared_error: 0.1556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:14:02.522954: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:310] gpu_async_0 cuMemAllocAsync failed to allocate 154537248 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 142802944/4086169600\n",
      "2024-10-20 21:14:02.522999: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:315] Stats: Limit:                      2919432192\n",
      "InUse:                       272057300\n",
      "MaxInUse:                    426594544\n",
      "NumAllocs:                    72820883\n",
      "MaxAllocSize:                154537248\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-10-20 21:14:02.524831: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:64] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2024-10-20 21:14:02.524855: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 4, 178846\n",
      "2024-10-20 21:14:02.524868: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 8, 9\n",
      "2024-10-20 21:14:02.524880: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 16, 5\n",
      "2024-10-20 21:14:02.524894: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 512, 13\n",
      "2024-10-20 21:14:02.524906: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 624, 1\n",
      "2024-10-20 21:14:02.524919: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 1024, 17\n",
      "2024-10-20 21:14:02.524931: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 1028, 1\n",
      "2024-10-20 21:14:02.524945: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 1232, 1\n",
      "2024-10-20 21:14:02.524958: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 2048, 18\n",
      "2024-10-20 21:14:02.524971: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 4800, 5\n",
      "2024-10-20 21:14:02.524984: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 7200, 1\n",
      "2024-10-20 21:14:02.524996: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 65536, 14\n",
      "2024-10-20 21:14:02.525011: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 189600, 1\n",
      "2024-10-20 21:14:02.525023: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 262144, 20\n",
      "2024-10-20 21:14:02.525036: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 524288, 5\n",
      "2024-10-20 21:14:02.525049: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 528384, 3\n",
      "2024-10-20 21:14:02.525061: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 634880, 5\n",
      "2024-10-20 21:14:02.525075: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 921600, 1\n",
      "2024-10-20 21:14:02.525090: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 1890304, 5\n",
      "2024-10-20 21:14:02.525103: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 1920000, 6\n",
      "2024-10-20 21:14:02.525115: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 2457600, 7\n",
      "2024-10-20 21:14:02.525127: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 24268800, 4\n",
      "2024-10-20 21:14:02.525140: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:67] 121344256, 1\n",
      "2024-10-20 21:14:02.525158: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:98] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 3858759680\n",
      "2024-10-20 21:14:02.525176: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 272057300\n",
      "2024-10-20 21:14:02.525192: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 3992977408\n",
      "2024-10-20 21:14:02.525207: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:102] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 426594544\n",
      "E0000 00:00:1729448042.525246   23487 dnn.cc:1173] OOM when allocating tensor with shape[154537248] and type uint8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n",
      "2024-10-20 21:14:02.525310: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at cudnn_rnn_ops.cc:2182 : INTERNAL: Failed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 128, 128, 1, 23700, 2, 128] \n",
      "2024-10-20 21:14:02.525397: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INTERNAL: Failed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 128, 128, 1, 23700, 2, 128] \n",
      "\t [[{{function_node __inference_one_step_on_data_42265691}}{{node gradient_tape/functional_1/lstm_3_1/CudnnRNNBackpropV3}}]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/functional_1/lstm_3_1/CudnnRNNBackpropV3 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_23402/1860495650.py\", line 10, in <module>\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 70, in train_step\n\nFailed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 128, 128, 1, 23700, 2, 128] \n\t [[{{node gradient_tape/functional_1/lstm_3_1/CudnnRNNBackpropV3}}]] [Op:__inference_one_step_on_iterator_42265832]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\t\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      5\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_both_epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m_val_\u001b[39m\u001b[38;5;132;01m{val_mean_squared_error:0.4f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39mtrain_generator,\n\u001b[1;32m     12\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     13\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     15\u001b[0m \tcallbacks\u001b[38;5;241m=\u001b[39m[checkpoint])\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/functional_1/lstm_3_1/CudnnRNNBackpropV3 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_23402/1860495650.py\", line 10, in <module>\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/home/dmytrot/miniconda3/envs/rapids-24.10/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 70, in train_step\n\nFailed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 128, 128, 1, 23700, 2, 128] \n\t [[{{node gradient_tape/functional_1/lstm_3_1/CudnnRNNBackpropV3}}]] [Op:__inference_one_step_on_iterator_42265832]"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    monitor='val_mean_squared_error',\n",
    "    save_best_only=True,\n",
    "    filepath='lstm_both_epoch{epoch:02d}_val_{val_mean_squared_error:0.4f}.keras'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    verbose=1,\n",
    "\tcallbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
